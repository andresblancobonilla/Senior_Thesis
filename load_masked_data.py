# -*- coding: utf-8 -*-
"""load_masked_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p25S9jO8VkpArFiGMsOs_OBidkGZr0r3
"""

import pickle
import glob
import time
import numpy as np
import os
import cv2
from pycocotools.coco import COCO
import PIL
import requests
from PIL import Image, ImageDraw
from tqdm import tqdm
import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
from skimage import transform

class Dataset(Dataset):
    def __init__(self, img_paths, img_labels, transform=T.ToTensor()):
        self.img_paths = img_paths
        self.img_labels = img_labels
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, index):
        ID = self.img_paths[index]
        img = Image.open(ID).convert('RGB')
        X = self.transform((img, ID))
        y = self.img_labels[ID]

        return X, y, ID


class MyCompose(object):
    def __init__(self, transforms):
        self.transforms = transforms

    def __call__(self, imgt):
        img, ID = imgt
        for t in self.transforms:
            if (t.__class__.__name__ in ["FullNoBg", "MaskSegm","MaskRect", "MaskRectNoBg", "MaskSegmNoBg",
                                         "MaskRectFace", "MaskRectFaceHands", "MaskRectFaceHandsNoBg",
                                         "MaskBrightnessJitter", "MaskBrightnessJitterNoBg",
                                         "MaskFaceBrightnessJitter","MaskFaceBrightnessJitterNoBg",
                                         "MaskSkinNoBg", "MaskSegmLargest","MaskSegmLargestNoBg",
                                         "MaskSegmLargestInverse", "RandomCropKeepPerson","ShiftPerson",
                                         "BodyKeypointsOnly", "FaceKeypointsOnly", "RHandKeypointsOnly",
                                         "LHandKeypointsOnly","HandKeypointsOnly","FootKeypointsOnly",
                                         "HandFootKeypointsOnly","BodyFaceKeypointsOnly", "BodyHandFootKeypointsOnly", 
                                         "AllKeypointsOnly"]):
              img = t(img, ID)
            else:
              img = t(img)
        return img


class Grayscale(object):
    """Make image grayscale.

    Args:
        None
    """
    def __init__(self):
        pass


    def __call__(self, img):

        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        gs_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        cv2_image = cv2.cvtColor(gs_image, cv2.COLOR_GRAY2BGR)
        cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
        changed_tensor = T.ToTensor()(cv2_image)
        return changed_tensor


class FullNoBg(object):
    """Mask the background of the image.

    Args:
        coco: coco object.
    """

    def __init__(self, coco):
        self.coco = coco

    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)
        object_anns = self.coco.loadAnns(object_ids)
        object_mask = np.zeros(image.shape, dtype=np.uint8)
        mask = np.zeros(image.shape, dtype=np.uint8)

        black_image = np.zeros(image.shape, np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        colors = []
        avg_image = np.zeros(image.shape, np.uint)
        dim1, dim2 = image.shape[0], image.shape[1]
        for channel in range(3):
            mean_color = np.mean(image[:,:,channel]).astype(np.uint8)
            layer = np.full((dim1, dim2), mean_color)
            colors.append(layer)
        avg_image = np.stack(colors)
        avg_image = np.moveaxis(avg_image, 0, -1)


        cv2.fillPoly(object_mask, get_mask_polygons(object_anns), ignore_mask_color)
        cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
        mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
        masked_cv2_image = cv2.bitwise_and(image, mask) + cv2.bitwise_and(black_image, mask_inverse)
        #reorder axes of image
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        #masked_pil_image = Image.fromarray(masked_cv2_image)
        return masked_tensor

class MaskSegm(object):
    """Segmentation mask the person in the image (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
        mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask

        masked_cv2_image = cv2.bitwise_and(black_image, mask) + cv2.bitwise_and(image, mask_inverse)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor


class MaskRect(object):
    """Mask the bounding box of the person in the image (rectangular mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        anns = self.coco.loadAnns(person_ids)
        for ann in anns:
            x, y, width, height = ann['bbox']
            start, end = (int(x), int(y)), (int(x + width), int(y + height))
            masked_cv2_image = cv2.rectangle(image, end, start, (0, 0, 0), -1)

        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor


class MaskRectNoBg(object):
    """Mask the background and the bounding box of the person in the image (rectangular mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        anns = self.coco.loadAnns(person_ids)
        masked_cv2_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
            x, y, width, height = ann['bbox']
            x0, y0, x1, y1 = int(x), int(y), int(x + width), int(y + height)
            masked_cv2_image[y0:y1, x0:x1] = white_image[y0:y1, x0:x1]

        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor


class MaskSegmNoBg(object):
    """Mask the background and segmentation mask the person in the image (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)
        object_anns = self.coco.loadAnns(object_ids)
        object_mask = np.zeros(image.shape, dtype=np.uint8)
        mask = np.zeros(image.shape, dtype=np.uint8)

        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        colors = []
        avg_image = np.zeros(image.shape, np.uint)
        dim1, dim2 = image.shape[0], image.shape[1]
        for channel in range(3):
            mean_color = np.mean(image[:,:,channel]).astype(np.uint8)
            layer = np.full((dim1, dim2), mean_color)
            colors.append(layer)
        avg_image = np.stack(colors)
        avg_image = np.moveaxis(avg_image, 0, -1)

        cv2.fillPoly(object_mask, get_mask_polygons(object_anns), ignore_mask_color)
        cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
        mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
        masked_cv2_image = cv2.bitwise_and(black_image, mask) + cv2.bitwise_and(white_image, mask_inverse)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class MaskRectFace(object):
    """Mask the bounding box of the face of person in the image (rectangular mask).

    Args:
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco_wb_anns):
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        for ann in anns:
            x, y, width, height = ann['face_box']
            start, end = (int(x), int(y)), (int(x + width), int(y + height))
            masked_cv2_image = cv2.rectangle(image, end, start, (0, 0, 0), -1)

        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class MaskRectFaceHands(object):
    """Mask the bounding box of the face and left and right hands of person in the image (rectangular mask).

    Args:
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco_wb_anns):
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]

        for ann in anns:
            for bbox in ['face_box', 'lefthand_box', 'righthand_box']:
              x, y, width, height = ann[bbox]
              start, end = (int(x), int(y)), (int(x + width), int(y + height))

              masked_cv2_image = cv2.rectangle(image, end, start, (0, 0, 0), -1)

        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor



class MaskBrightnessJitter(object):
    """Randomly change the brightness of the person in the image using
       segmentation annotations.

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
      person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
      object_ids = list(set(ann_ids) ^ set(person_ids))
      anns = self.coco.loadAnns(person_ids)
      jittered_image = T.ColorJitter(brightness=1)(img)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)

      mask = np.zeros(image.shape, dtype=np.uint8)
      channel_count = image.shape[2]
      ignore_mask_color = (255,)*channel_count
      for ann in anns:
        cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
      mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
      final_image = cv2.bitwise_and(jittered_image, mask) + cv2.bitwise_and(image, mask_inverse)
      masked_cv2_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_cv2_image)
      
      return masked_tensor

class MaskBrightnessJitterNoBg(object):
    """Randomly change the brightness of the person in the image using
       segmentation annotations.

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
      person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
      object_ids = list(set(ann_ids) ^ set(person_ids))
      object_anns = self.coco.loadAnns(object_ids)
      object_mask = np.zeros(image.shape, dtype=np.uint8)
      anns = self.coco.loadAnns(person_ids)

      jittered_image = T.ColorJitter(brightness=1)(img)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)

      mask = np.zeros(image.shape, dtype=np.uint8)
      white_image = np.full(image.shape, 255, np.uint8)
      channel_count = image.shape[2]
      ignore_mask_color = (255,)*channel_count
      cv2.fillPoly(object_mask, get_mask_polygons(object_anns), ignore_mask_color)
      cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
      mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
      final_image = cv2.bitwise_and(jittered_image, mask) + cv2.bitwise_and(white_image, mask_inverse)
      masked_cv2_image = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_cv2_image)
      
      return masked_tensor

class MaskFaceBrightnessJitter(object):
    """Randomly change the brightness of the person in the image using
       segmentation annotations.

    Args:
        coco: coco object.
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
      person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
      object_ids = list(set(ann_ids) ^ set(person_ids))
      anns = self.coco.loadAnns(person_ids)
      jittered_image = T.ColorJitter(brightness=1)(img)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)

      mask = np.zeros(image.shape, dtype=np.uint8)
      channel_count = image.shape[2]
      ignore_mask_color = (255,)*channel_count
      cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
      mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
      jittered_image = cv2.bitwise_and(jittered_image, mask) + cv2.bitwise_and(image, mask_inverse)
      anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
      for ann in anns:
          for bbox in ['face_box']:
            x, y, width, height = ann[bbox]
            start, end = (int(x), int(y)), (int(x + width), int(y + height))

            masked_cv2_image = cv2.rectangle(jittered_image, end, start, (0, 0, 0), -1)
      masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_cv2_image)
      
      return masked_tensor

class MaskFaceBrightnessJitterNoBg(object):

    """Randomly change the brightness of the person in the image using
       segmentation annotations.

    Args:
        coco: coco object.
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
      person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
      object_ids = list(set(ann_ids) ^ set(person_ids))
      object_anns = self.coco.loadAnns(object_ids)
      object_mask = np.zeros(image.shape, dtype=np.uint8)
      anns = self.coco.loadAnns(person_ids)

      jittered_image = T.ColorJitter(brightness=1)(img)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2BGR)

      mask = np.zeros(image.shape, dtype=np.uint8)
      white_image = np.full(image.shape, 255, np.uint8)
      channel_count = image.shape[2]
      ignore_mask_color = (255,)*channel_count
      cv2.fillPoly(object_mask, get_mask_polygons(object_anns), ignore_mask_color)
      cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
      mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
      jittered_image = cv2.bitwise_and(jittered_image, mask) + cv2.bitwise_and(white_image, mask_inverse)
      anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]

      for ann in anns:
          for bbox in ['face_box']:
            x, y, width, height = ann[bbox]
            start, end = (int(x), int(y)), (int(x + width), int(y + height))

            masked_cv2_image = cv2.rectangle(jittered_image, end, start, (0, 0, 0), -1)
  
      masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_cv2_image)
      
      return masked_tensor

class MaskSkin(object):

    """Mask the skin of the person in the image.

    Args:
        None.
    """
    def __init__(self):
      pass


    def __call__(self, img):
      # calculate minimum area rectange that covers all four points
      # x_min = min(point[0] for point in point_list)
      # x_max = max(point[0] for point in point_list)
      # y_min = min(point[1] for point in point_list)
      # y_max = max(point[1] for point in point_list)

      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
      HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255)) 
      HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))

      #converting from gbr to YCbCr color space
      img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
      #skin color range for hsv color space 
      YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135)) 
      YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))

      #merge skin detection (YCbCr and hsv)
      global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)
      global_mask=cv2.medianBlur(global_mask,3)
      global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))

      HSV_result = cv2.bitwise_not(HSV_mask)
      YCrCb_result = cv2.bitwise_not(YCrCb_mask)
      global_result = cv2.bitwise_not(global_mask)
      global_result = cv2.cvtColor(global_result, cv2.COLOR_RGB2BGR)
      global_result = cv2.bitwise_and(global_result, image)

      # black_image = np.zeros(image.shape, np.uint8)
      # channel_count = image.shape[2]
      # ignore_mask_color = (255,)*channel_count

      # mask_inverse = np.ones(global_result.shape).astype(np.uint8)*255 - global_result

      # masked_cv2_image = cv2.bitwise_and(black_image, global_result) + cv2.bitwise_and(image, mask_inverse)

      masked_cv2_image = cv2.cvtColor(global_result, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_cv2_image)

      return masked_tensor
      

class MaskSkinNoBg(object):

    """Mask the background and the skin of the person in the image.

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
      self.coco = coco


    def __call__(self, img, ID):

      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
      HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255))
      HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))

      #converting from gbr to YCbCr color space
      img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
      #skin color range for hsv color space
      YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135))
      YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))

      #merge skin detection (YCbCr and hsv)
      global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)
      global_mask=cv2.medianBlur(global_mask,3)
      global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))

      HSV_result = cv2.bitwise_not(HSV_mask)
      YCrCb_result = cv2.bitwise_not(YCrCb_mask)
      global_result = cv2.bitwise_not(global_mask)
      global_result = cv2.cvtColor(global_result, cv2.COLOR_RGB2BGR)
      global_result = cv2.bitwise_and(global_result, image)

      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
      person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
      object_ids = list(set(ann_ids) ^ set(person_ids))
      anns = self.coco.loadAnns(person_ids)
      object_anns = self.coco.loadAnns(object_ids)
      object_mask = np.zeros(image.shape, dtype=np.uint8)
      mask = np.zeros(image.shape, dtype=np.uint8)

      black_image = np.zeros(image.shape, np.uint8)
      white_image = np.full(image.shape, 255, np.uint8)
      channel_count = image.shape[2]
      ignore_mask_color = (255,)*channel_count

      colors = []
      avg_image = np.zeros(image.shape, np.uint)
      dim1, dim2 = image.shape[0], image.shape[1]
      for channel in range(3):
            mean_color = np.mean(image[:,:,channel]).astype(np.uint8)
            layer = np.full((dim1, dim2), mean_color)
            colors.append(layer)
      avg_image = np.stack(colors)
      avg_image = np.moveaxis(avg_image, 0, -1)

      cv2.fillPoly(object_mask, get_mask_polygons(object_anns), ignore_mask_color)
      cv2.fillPoly(mask, get_mask_polygons(anns), ignore_mask_color)
      mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask
      masked_cv2_image = cv2.bitwise_and(black_image, mask) + cv2.bitwise_and(white_image, mask_inverse)


      masked_cv2_image = cv2.bitwise_or(masked_cv2_image, global_result)
      masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)

      masked_tensor = T.ToTensor()(masked_cv2_image)

      return masked_tensor

class BrightnessJitterSkin(object):
    """Randomly change the brightness of the person in the image using
       segmentation annotations.

    Args:
        None
    """
    def __init__(self):
      pass


    def __call__(self, img):
      image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
      jittered_image = T.ColorJitter(brightness=1)(img)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_RGB2GRAY)
      jittered_image = cv2.cvtColor(np.array(jittered_image), cv2.COLOR_GRAY2BGR)
      img_HSV = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
      HSV_mask = cv2.inRange(img_HSV, (0, 15, 0), (17,170,255))
      HSV_mask = cv2.morphologyEx(HSV_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))
      img_YCrCb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
      YCrCb_mask = cv2.inRange(img_YCrCb, (0, 135, 85), (255,180,135))
      YCrCb_mask = cv2.morphologyEx(YCrCb_mask, cv2.MORPH_OPEN, np.ones((3,3), np.uint8))
      global_mask=cv2.bitwise_and(YCrCb_mask,HSV_mask)
      global_mask=cv2.medianBlur(global_mask,3)
      global_mask = cv2.morphologyEx(global_mask, cv2.MORPH_OPEN, np.ones((4,4), np.uint8))
      HSV_result = cv2.bitwise_not(HSV_mask)
      YCrCb_result = cv2.bitwise_not(YCrCb_mask)
      global_result = cv2.bitwise_not(global_mask)
      global_result = cv2.cvtColor(global_result, cv2.COLOR_RGB2BGR)
      gs_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
      gs_image = cv2.cvtColor(gs_image, cv2.COLOR_GRAY2BGR)
      mask_inverse = np.ones(global_result.shape).astype(np.uint8)*255 - global_result
      masked_image = cv2.bitwise_and(jittered_image, mask_inverse) + cv2.bitwise_and(gs_image, global_result)
      masked_image = cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB)
      masked_tensor = T.ToTensor()(masked_image)


      return masked_tensor

class MaskSegmLargestInverse(object):
    """Segmentation mask the person in the image with the largest bounding box (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(image, mask)

        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class ShiftPerson(object):
    """Segmentation mask the person in the image with the largest bounding box (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(image, mask)

        largest_ann = get_largest_ann(anns)
        # print(largest_ann['bbox'])
        x, y, width, height = largest_ann['bbox']
        x, y, width, height = int(x), int(y), int(width), int(height)
        cropped_cv2_image = masked_cv2_image[y:y + height, x:x + width]
        # print(cropped_cv2_image.shape)
        shifted_cv2_image = np.zeros(image.shape, np.uint8)

        # if shifted_cv2_image.shape[0] != 640:
        #   print(shifted_cv2_image.shape[0])

        if shifted_cv2_image.shape[1] == width:
          new_x = 0
        else:
          new_x = np.random.randint(0, shifted_cv2_image.shape[1] - width)

        if shifted_cv2_image.shape[0] == height:
          new_y = 0
        else:
          new_y = np.random.randint(0, shifted_cv2_image.shape[0] - height)

        # print(width, height, cropped_cv2_image.shape[0],cropped_cv2_image.shape[1])

        shifted_cv2_image[new_y:new_y+height, new_x:new_x+width] = cropped_cv2_image
        shifted_cv2_image = cv2.cvtColor(shifted_cv2_image, cv2.COLOR_BGR2RGB)
        shifted_tensor = T.ToTensor()(shifted_cv2_image)
        return shifted_tensor




def get_largest_ann(anns):
    largest_bbox_area = 0
    largest_ann = None
    for ann in anns:
      x, y, width, height = ann['bbox']
      bbox_area = width * height
      if (bbox_area > largest_bbox_area):
        largest_bbox_area = bbox_area
        largest_ann = ann
    return largest_ann
    

def get_largest_mask_polygons(anns):
    polygons = []
    largest_ann = get_largest_ann(anns)
    
    for seg in largest_ann['segmentation']:
        poly = np.array(seg).reshape((len(seg)//2, 2))
        poly = poly.astype(np.int32)
        polygons.append(poly)
    return polygons


class MaskSegmLargest(object):
    """Segmentation mask the person in the image with the largest bounding box (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)
        mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask

        masked_cv2_image = cv2.bitwise_and(black_image, mask) + cv2.bitwise_and(image, mask_inverse)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class MaskSegmLargestNoBg(object):
    """Segmentation mask the background and the person in the image with the largest bounding box (silhouette mask).

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)
        mask_inverse = np.ones(mask.shape).astype(np.uint8)*255 - mask

        masked_cv2_image = cv2.bitwise_and(black_image, mask) + cv2.bitwise_and(image, mask_inverse)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        PIL_image = T.ToPILImage()(masked_cv2_image)
        masked_tensor = FullNoBg(coco = self.coco)(PIL_image, ID)
        return masked_tensor

class EdgeDetection(object):
    """Segmentation mask the person in the image with the largest bounding box (silhouette mask).

    Args:
        None
    """
    def __init__(self):
        pass


    def __call__(self, img):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)
        blurred_image = cv2.GaussianBlur(image, (5,5), 0)
        high_thresh, thresh_image = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        low_thresh = high_thresh / 2
        edge_cv2_image = cv2.Canny(blurred_image, low_thresh, high_thresh)
        edge_cv2_image = cv2.cvtColor(edge_cv2_image, cv2.COLOR_GRAY2RGB)
        masked_tensor = T.ToTensor()(edge_cv2_image)
        return masked_tensor

class RandomCropKeepPerson(object):
    """Double the size of the image and randomly take a 224x224 crop,
    ensuring that the bounding box of the largest person is kept intact.

    Args:
        coco: coco object.
    """
    def __init__(self, coco):
        self.coco = coco


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        largest_ann = get_largest_ann(anns)
        x, y, width, height = largest_ann['bbox']
        start, end = (int(x), int(y)), (int(x + width), int(y + height))

        bottom_pad = image.shape[1] - end[1]
        right_pad = image.shape[0] - end[0]

        if bottom_pad <= 0:
          random_bottom_pad = 0
        else:
          random_bottom_pad = np.random.randint(0, bottom_pad)

        if right_pad <= 0:
          random_right_pad = 0
        else:
          random_right_pad = np.random.randint(0, right_pad)

        # pick random point from 0 to start, then crop_size is person + pad
        if start[0] == 0:
          crop_x_start = 0
        else:
          crop_x_start = np.random.randint(0, start[0])

        if start[1] == 0:
          crop_y_start = 0
        else:
          crop_y_start = np.random.randint(0, start[1])

        crop_width = int(start[0] - crop_x_start + width + random_right_pad)
        crop_height = int(start[1] - crop_y_start + height + random_bottom_pad)


        cropped_cv2_image = image[crop_y_start:crop_y_start + crop_height,
                                  crop_x_start:crop_x_start + crop_width]


        cropped_cv2_image = cv2.cvtColor(cropped_cv2_image, cv2.COLOR_BGR2RGB)
        cropped_tensor = T.ToTensor()(cropped_cv2_image)
        return cropped_tensor


class ChangeLuminance(object):
    """Change the luminance (LAB) of every pixel in the image
    to the same constant.

    Args:
        None
    """
    def __init__(self):
        pass


    def __call__(self, img):

        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        lab_image[:,:,0] = 255 / 2
        cv2_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)
        cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
        changed_tensor = T.ToTensor()(cv2_image)
        return changed_tensor

class ChangeBrightness(object):
    """Change the brightness (HSV value) of every pixel in the image
    to the same constant.

    Args:
        None
    """
    def __init__(self):
        pass


    def __call__(self, img):

        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        hsv_image[:,:,2] = 255 / 2
        cv2_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)
        cv2_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
        changed_tensor = T.ToTensor()(cv2_image)
        return changed_tensor

class BodyKeypointsOnly(object):
    """Mask everything except the 68 face keypoints of the person.

    Args:
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):


        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
            body_kpts = ann['body_kpts']
            body_kpts = [body_kpts[i:i+3] for i in range(0, len(body_kpts), 3)]
            for kpt in body_kpts:
              #print(kpt)
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class FaceKeypointsOnly(object):
    """Mask everything except the 68 face keypoints of the person.

    Args:
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):


        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
            face_kpts = ann['face_kpts']
            face_kpts = [face_kpts[i:i+3] for i in range(0, len(face_kpts), 3)]
            for kpt in face_kpts:
              #print(kpt)
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class HandFootKeypointsOnly(object):
    """Mask everything except the 42 hand and 6 feet keypoints of the person.

    Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['foot_kpts','lefthand_kpts','righthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class HandKeypointsOnly(object):
    """Mask everything except the 42 hand and 6 feet keypoints of the person.

    Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['lefthand_kpts','righthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class FootKeypointsOnly(object):
    """Mask everything except the 42 hand and 6 feet keypoints of the person.

    Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['foot_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class RHandKeypointsOnly(object):
    """Mask everything except the 42 hand and 6 feet keypoints of the person.

    Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['righthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class LHandKeypointsOnly(object):
    """Mask everything except the 42 hand and 6 feet keypoints of the person.

    Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['lefthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor

class BodyFaceKeypointsOnly(object):
    """Mask everything except the body and face keypoints of the person.

  Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['body_kpts', 'face_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor
       

class BodyHandFootKeypointsOnly(object):
    """Mask everything except the 17 body, hand, and foot keypoints of the person.

  Args:
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['face_kpts','foot_kpts','lefthand_kpts','righthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor


class AllKeypointsOnly(object):
    """Mask everything except the 133 face, body, hand, and foot keypoints of the person.
        coco: coco object
        coco_wb_anns: dict of coco whole body annotations.
    """
    def __init__(self, coco, coco_wb_anns):
        self.coco = coco
        self.coco_wb_anns = coco_wb_anns


    def __call__(self, img, ID):
        image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        anns = self.coco_wb_anns[int(ID.split('_')[-1].split('.')[0])]
        mask = np.zeros(image.shape[:2], dtype=np.uint8)
        black_image = np.zeros(image.shape, np.uint8)
        white_image = np.full(image.shape, 255, np.uint8)
        for ann in anns:
          kpt_keys = ['body_kpts', 'face_kpts',
                      'foot_kpts','lefthand_kpts','righthand_kpts']
          for kpt_key in kpt_keys:
            kpts = ann[kpt_key]
            kpts = [kpts[i:i+3] for i in range(0, len(kpts), 3)]
            for kpt in kpts:
              visible = kpt[2]
              x_coord = int(kpt[0])
              y_coord = int(kpt[1])
              if visible > 0 and y_coord < image.shape[0] and x_coord < image.shape[1]:
                mask[y_coord, x_coord] = 255
        masked_cv2_image = cv2.bitwise_and(white_image, white_image, mask = mask)
        ann_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), iscrowd=False)
        person_ids = self.coco.getAnnIds(int(ID.split('_')[-1].split('.')[0]), catIds=[1], iscrowd=False)
        object_ids = list(set(ann_ids) ^ set(person_ids))
        anns = self.coco.loadAnns(person_ids)

        mask = np.zeros(image.shape, dtype=np.uint8)
        channel_count = image.shape[2]
        ignore_mask_color = (255,)*channel_count

        cv2.fillPoly(mask, get_largest_mask_polygons(anns), ignore_mask_color)

        masked_cv2_image = cv2.bitwise_and(masked_cv2_image, mask)
        masked_cv2_image = cv2.cvtColor(masked_cv2_image, cv2.COLOR_BGR2RGB)
        masked_tensor = T.ToTensor()(masked_cv2_image)
        return masked_tensor



def get_mask_polygons(anns):
    polygons = []
    for ann in anns:
        for seg in ann['segmentation']:
            poly = np.array(seg).reshape((len(seg)//2, 2))
            poly = poly.astype(np.int32)
            polygons.append(poly)
    return polygons

def create_dataset(labels_path, B=200, train=True, res=224, mask_transform=None):

    img_labels = pickle.load(open(labels_path, 'rb'))
    img_paths = sorted(list(img_labels.keys()))
    
    if (mask_transform and "FaceHandFoot" in mask_transform.__class__.__name__ or "AllKeypoints" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['face_valid'] or ann['righthand_valid'] or ann['lefthand_valid'] or ann['foot_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "Face" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['face_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "HandFoot" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['righthand_valid'] or ann['lefthand_valid'] or ann['foot_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "Foot" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['foot_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "RHand" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['righthand_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "LHand" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['lefthand_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    elif (mask_transform and "Hand" in mask_transform.__class__.__name__):
        wb_anns = pickle.load(open("/content/drive/MyDrive/2023-2024/Thesis/whole_body_annotations.pkl", "rb"))
        cleaned_img_labels = {}
        for img_path, img_label in img_labels.items():
            img_id = int(img_path.split('_')[-1].split('.')[0])
            for ann in wb_anns[img_id]:
                if ann['lefthand_valid'] or ann['righthand_valid']:
                    cleaned_img_labels[img_path] = img_label
        img_labels = cleaned_img_labels
        img_paths = sorted(list(cleaned_img_labels.keys()))

    

    # Common from here
    normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

    if train:
        if (mask_transform):
            transform = MyCompose([
                mask_transform,
                T.RandomResizedCrop(224),
                T.Resize(res),
                T.Resize(224, interpolation = T.InterpolationMode.NEAREST),
                T.RandomHorizontalFlip(),
                normalize
                ])
        else:
            transform = MyCompose([
                    T.RandomResizedCrop(224),
                    T.Resize(res),
                    T.RandomHorizontalFlip(),
                    T.Resize(224, interpolation = T.InterpolationMode.NEAREST),
                    T.ToTensor(),
                    normalize
                ])
        shuffle = True

    else:
        if (mask_transform):
            transform = MyCompose([
                   mask_transform,
                   T.Resize(256),
                   T.CenterCrop(224),
                   T.Resize(res),
                   T.Resize(224, interpolation = T.InterpolationMode.NEAREST_EXACT),
                   normalize
            ])

                

        else:
            transform = MyCompose([
                   T.Resize(256),
                   T.CenterCrop(224),
                   T.Resize(res),
                   T.Resize(224, interpolation = T.InterpolationMode.NEAREST_EXACT),
                   T.ToTensor(),
                   normalize
            ])

        shuffle = False

    dset = Dataset(img_paths, img_labels, transform)
    loader = DataLoader(dset, batch_size=B, shuffle=shuffle, num_workers=1)
    return loader